{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ccb4b6-05e4-417d-8ebe-5477d16550b8",
   "metadata": {},
   "source": [
    "# PyTorch：view() 与 reshape() 区别详解\n",
    "<font size=4 color=red>\n",
    "    总之，两者都是用来重塑tensor的shape的。view只适合对满足连续性条件（contiguous）的tensor进行操作，而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干，如果view不能干就可以用reshape来处理。别看目录挺多，但内容很细呀~其实原理并不难啦~我们开始吧~ \n",
    "</font></br>\n",
    "\n",
    "\n",
    "\n",
    "## 主要内容\n",
    "\n",
    "### 一、PyTorch中tensor的存储方式\n",
    "\n",
    "    1、PyTorch张量存储的底层原理\n",
    "\n",
    "    2、PyTorch张量的步长（stride）属性\n",
    "\n",
    "### 二、对“视图(view)”字眼的理解\n",
    "\n",
    "### 三、view() 和reshape() 的比较\n",
    "\n",
    "    1、对 torch.Tensor.view() 的理解\n",
    "\n",
    "    2、对 torch.reshape() 的理解\n",
    "\n",
    "### 四、总结\n",
    "\n",
    "### 一、PyTorch中tensor的存储方式\n",
    "<font size=4>想要深入理解view与reshape的区别，首先要理解一些有关PyTorch张量存储的底层原理，比如tensor的头信息区（Tensor）和存储区 （Storage）以及tensor的步长Stride。不用慌，这部分的原理其实很简单的(^-^)!</font>\n",
    "\n",
    "<font size=5>1、PyTorch张量存储的底层原理</font></br>\n",
    "<font size=4>tensor数据采用头信息区（Tensor）和存储区 （Storage）分开存储的形式，如图1所示。变量名以及其存储的数据是分为两个区域分别存储的。比如，我们定义并初始化一个tensor，tensor名为A，A的形状size、步长stride、数据的索引等信息都存储在头信息区，而A所存储的真实数据则存储在存储区。另外，如果我们对A进行截取、转置或修改等操作后赋值给B，则B的数据共享A的存储区，存储区的数据数量没变，变化的只是B的头信息区对数据的索引方式。</font>\n",
    "</br>\n",
    "![avatar](http://image109.360doc.com/DownloadImg/2021/03/1709/217856618_1_20210317091321662)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-ml(python3.7)",
   "language": "python",
   "name": "study-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
