{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f8bee9-91a7-46b7-bc91-c9033e6367c8",
   "metadata": {},
   "source": [
    "# 2.4. 微积分\n",
    "<font size=4>\n",
    "    在2500年前，古希腊人把一个多边形分成三角形，并把它们的面积相加，才找到计算多边形面积的方法。 为了求出曲线形状（比如圆）的面积，古希腊人在这样的形状上刻内接多边形。内接多边形的等长边越多，就越接近圆。 这个过程也被称为逼近法（method of exhaustion）。\n",
    "\n",
    "事实上，逼近法就是积分（integral calculus）的起源， 我们将在 sec_integral_calculus中详细描述。 2000多年后，微积分的另一支，微分（differential calculus）被发明出来。 在微分学最重要的应用是优化问题，即考虑如何把事情做到最好。 正如在 2.3.10.1节中讨论的那样， 这种问题在深度学习中是无处不在的。\n",
    "\n",
    "在深度学习中，我们“训练”模型，不断更新它们，使它们在看到越来越多的数据时变得越来越好。 通常情况下，变得更好意味着最小化一个损失函数（loss function）， 即一个衡量“我们的模型有多糟糕”这个问题的分数。 最终，我们真正关心的是生成一个模型，它能够在从未见过的数据上表现良好。 但“训练”模型只能将模型与我们实际能看到的数据相拟合。 因此，我们可以将拟合模型的任务分解为两个关键问题：\n",
    "\n",
    "- 优化（optimization）：用模型拟合观测数据的过程；\n",
    "\n",
    "- 泛化（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。\n",
    "\n",
    "为了帮助你在后面的章节中更好地理解优化问题和方法， 本节提供了一个非常简短的入门教程，帮你快速掌握深度学习中常用的微分知识。\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217fda2-aa7e-49fe-ada8-1098d013a2ed",
   "metadata": {},
   "source": [
    "## 2.4.1. 导数和微分\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-ml(python3.7)",
   "language": "python",
   "name": "study-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
