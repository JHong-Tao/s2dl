{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb0d650b-8a25-45c2-9975-e6dde15497cb",
   "metadata": {},
   "source": [
    "# Jupyter 快捷键\n",
    "- 模式切换\n",
    "    - esc 切换到命令模式\n",
    "    - Enter 切换到编辑模式\n",
    "- 编辑模式常用快捷键\n",
    "    - Ctrl + ]缩进\n",
    "    - Ctrl + Y 重做\n",
    "    - Ctrl + Enter 运行当前单元\n",
    "    - Shift + Enter 运行当前单，若无下一个单元，则新建下一个单元\n",
    "    - Alt + Enter 运行当前单元，并新建下一个单元\n",
    "- 命令模式常用快捷键\n",
    "    - Y:原单元转为 code\n",
    "    - M:原单元转为 Markdown\n",
    "    - R:原单元转为 源码格式\n",
    "    - A:在上方插入新单元\n",
    "    - B:在下方插入新单元\n",
    "    - DD:删除单元\n",
    "    - LL:中断内核\n",
    "    - OO:重启内核"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb140119-fe1d-4f25-847e-ddaa6487edcc",
   "metadata": {},
   "source": [
    "# 1. 什么是PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae56f7-b4bc-40f4-8e28-9ee294e15a6b",
   "metadata": {},
   "source": [
    "[PyTorch](https://pytorch.org/)是一个基于Python的科学计算库，它有如下特点：\n",
    "- 类似于Numpy,但是它可以使用GPU\n",
    "- 可以用它定义深度学习模型，可以灵活的进行深度学习模型的训练和使用\n",
    "- Tensors Tensor类似于Numpy的ndarray,唯一的区别是前者可以在GPU上加速运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e81168-e6f1-42d3-bdfd-1adab300c0da",
   "metadata": {},
   "source": [
    "## 1.1 Tensors\n",
    "- 导入torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905359df-80bb-4126-b609-fc33d9cfc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8a329-38c5-410f-b022-00a1e6a26eda",
   "metadata": {},
   "source": [
    "- 构造一个未初始化的矩阵：shape=5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45a87c6-6792-4687-a99a-bc12122b431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a4205-c2e2-4572-bd1c-d489e2168c67",
   "metadata": {},
   "source": [
    "- 构建一个随机初始化矩阵：shape=5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1397191-cc34-4d11-b89e-7999688874bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9107, 0.7353, 0.4210],\n",
      "        [0.3232, 0.2024, 0.1266],\n",
      "        [0.2547, 0.8111, 0.0194],\n",
      "        [0.9602, 0.5498, 0.5110],\n",
      "        [0.6287, 0.8993, 0.7994]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21050d9c-f6fd-4073-a771-63b23ebda307",
   "metadata": {},
   "source": [
    "- 构建一个全为0的，数据类型为long的矩阵：shape=5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e5f0f2-2e05-4a79-8664-4644a809e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ad1d2-32c5-40ab-8445-e796c641a468",
   "metadata": {},
   "source": [
    "- 从数据中直接构建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd691551-cb00-4465-a6bd-e03693247896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 3])\n",
      "1879043711688\n",
      "1879043521928\n"
     ]
    }
   ],
   "source": [
    "y = [5, 3]\n",
    "x = torch.tensor(y)\n",
    "print(x)\n",
    "print(id(x))\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661ce7e-cab1-44cf-8372-32d51454eb31",
   "metadata": {},
   "source": [
    "- 也可以从一个已有的tensor构建一个tensor。这些方法会重用原来tensor的特征，如数据类型和数据等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff6c370-b00d-477a-b6aa-0236ea263f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[0.6975, 0.3096, 0.5050],\n",
      "        [0.9831, 0.2105, 0.3983],\n",
      "        [0.7223, 0.0028, 0.5541],\n",
      "        [0.1235, 0.6245, 0.2283],\n",
      "        [0.7322, 0.2845, 0.8687]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3)   # new_*这个方法需要传递新tensor的sizes,也就是矩阵的形状\n",
    "print(x)\n",
    "\n",
    "y = torch.rand_like(x, dtype=torch.float)    # 穿甲一个与x形状相似的随机矩阵\n",
    "print(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.size())    # shape和size() 都是获取tensor的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324af6a-e9da-4573-be2b-482ff2f67dbc",
   "metadata": {},
   "source": [
    "## 1.2 Tensor的运算    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036564d-6ec8-43a2-82e7-3068d6bbb3de",
   "metadata": {},
   "source": [
    "- 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e78e98f-ce33-47ce-b211-420cdda8bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[0.6975, 0.3096, 0.5050],\n",
      "        [0.9831, 0.2105, 0.3983],\n",
      "        [0.7223, 0.0028, 0.5541],\n",
      "        [0.1235, 0.6245, 0.2283],\n",
      "        [0.7322, 0.2845, 0.8687]])\n",
      "tensor([[1.6975, 1.3096, 1.5050],\n",
      "        [1.9831, 1.2105, 1.3983],\n",
      "        [1.7223, 1.0028, 1.5541],\n",
      "        [1.1235, 1.6245, 1.2283],\n",
      "        [1.7322, 1.2845, 1.8687]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460aacbd-cd05-481e-bb86-3714fcc89ada",
   "metadata": {},
   "source": [
    "- add加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bad2a1bc-fa9e-450a-a58b-8f82ddc5e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6975, 1.3096, 1.5050],\n",
      "        [1.9831, 1.2105, 1.3983],\n",
      "        [1.7223, 1.0028, 1.5541],\n",
      "        [1.1235, 1.6245, 1.2283],\n",
      "        [1.7322, 1.2845, 1.8687]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c94c7-726b-4d61-983a-fb1c89e49a20",
   "metadata": {},
   "source": [
    "- 把加法的输出结果作为一个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cf04bfa-1343-4c7e-95ac-467052551332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6975, 1.3096, 1.5050],\n",
      "        [1.9831, 1.2105, 1.3983],\n",
      "        [1.7223, 1.0028, 1.5541],\n",
      "        [1.1235, 1.6245, 1.2283],\n",
      "        [1.7322, 1.2845, 1.8687]])\n",
      "tensor([[1.6975, 1.3096, 1.5050],\n",
      "        [1.9831, 1.2105, 1.3983],\n",
      "        [1.7223, 1.0028, 1.5541],\n",
      "        [1.1235, 1.6245, 1.2283],\n",
      "        [1.7322, 1.2845, 1.8687]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "print(result)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a0377c-5346-4b4f-adfa-22a4c17d24db",
   "metadata": {},
   "source": [
    "- in-place加法 （in-place:原地取代的意思）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b7d1608-13e5-4123-a974-57c9a999012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros(x.size())\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02df157-d291-4032-9cd1-bee978b916d7",
   "metadata": {},
   "source": [
    "- **注意：*\n",
    "    - 所有in-place运算都会的名称都是一下划线\"_\"结尾，这种运算会直接改变被操作变量的值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b82524-9fdb-4717-8447-342ef5d63f70",
   "metadata": {},
   "source": [
    "## 1.3 Tensor的索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bf4c9ae-b252-4007-874f-2661081c9514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65a366b0-1932-4d3e-9820-2a84e28ef8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])   # 取x的第1列，列标从0开始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52bbe1-86a1-4c5c-b352-d1205ce2ba8c",
   "metadata": {},
   "source": [
    "- Resizing:如果希望reshape tensor的形状可以使用：torch.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c5c65da-c77e-4de6-8166-1d6db2582087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(4, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1976f1e6-08c9-4a79-9707-c5faceae4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a553b-f7b8-4dd0-a99f-67c6489cf88a",
   "metadata": {},
   "source": [
    "- 通过设置一个维度为“-1”来进行自动推断tensor的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bb2ad78-0d8f-4379-8114-2b7aa7e31bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(-1,2,2)\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d4c0c-1d2f-4721-adad-bf440fc2c1ae",
   "metadata": {},
   "source": [
    "- 如果tensor中只包含一个元素，可以使用“.item()”方法，把tensor中的数值变成python的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d767be99-4155-4e86-9aa4-6bdbe2ad8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "1.0\n",
      "<class 'torch.Tensor'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(type(x))\n",
    "print(type(x.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141f437-6f57-49ce-819a-a924e35c39f3",
   "metadata": {},
   "source": [
    "## 1.4 Numpy和Tensor之间的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54715c-2955-44c5-8ce4-0fe4e9dcd9a2",
   "metadata": {},
   "source": [
    "- Torch Tensor可以和Numpy array无障碍的转换\n",
    "- Tensor 和 Numpy array之间会共享同一块数据内存，所以改变其中之一，两者的数据都会发生变化\n",
    "- 所有CPU上的Tensor都支持转成numpy或者从numpy转成Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38813651-e813-430e-b093-0b109114579c",
   "metadata": {},
   "source": [
    "- Tensor 转Numpy Array :   “.numpy()方法”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a8861ac-9eed-4ad5-88b7-d4e0728ff686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b57e63e4-b021-4977-a7ef-39ed1689db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a8b81-d664-4cd3-8cc5-31e5ba2f38ad",
   "metadata": {},
   "source": [
    "- 通过修改tensor的值来修改numpy中的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd58ddd8-7a9e-400a-943c-705530bb44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879043970456\n",
      "1879043967472\n",
      "tensor([4., 4., 4., 4., 4.])\n",
      "[4. 4. 4. 4. 4.]\n",
      "1879043970456\n",
      "1879043967472\n"
     ]
    }
   ],
   "source": [
    "print(id(a))\n",
    "print(id(b))\n",
    "# 修改tensor的值\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ecb2a-7393-4973-9d05-bd43bc2a2e59",
   "metadata": {},
   "source": [
    "- Numpy ndarray 转 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ed340c5-5666-486a-aa25-e76353ef8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04067f0-ba85-4f46-b26f-92dc3e3795e2",
   "metadata": {},
   "source": [
    "## 1.5 CUDA Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b311ae7-2921-461e-8915-187c0e8c0cf7",
   "metadata": {},
   "source": [
    "\".to()\"方法，将tensor转移到GPU上运行,也可以把GPU上的数据转移到CPU上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bdfae58-ff5e-4b95-90e3-2f0417c6ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu = torch.device('cuda')            # 获取GPU\n",
    "    x = torch.ones(4)                     # 创建一个CPU的tensor\n",
    "    y = torch.ones_like(x, device=gpu)    # 创建tensor的时候给它指定GPU\n",
    "    x = x.to(gpu)                         # 把x转移到GPU上\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871e7d4-725e-4373-8fec-d8dd8d45ae91",
   "metadata": {},
   "source": [
    "# 2. 全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db46219-b214-481e-92b0-d7f88cadd07a",
   "metadata": {},
   "source": [
    "## 2.1 numpy实现两层全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91c766-dbe9-4508-b193-6621d9d1ebaa",
   "metadata": {},
   "source": [
    "- 一个全连接ReLU神经网络，一个隐藏层，没有bias。用来从x预测y,使用$L_{2}$Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bdacbf-7835-4316-970c-c21c027f8238",
   "metadata": {},
   "source": [
    "- 这一实现完全使用numpy来计算前向神经网络，loss，和反向传播\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac6444-8af1-47ee-970e-778c04b75a4c",
   "metadata": {},
   "source": [
    "- numpy ndarray 是一个普通的n为array。它不知道任何关于深度学习或者梯度的知识，也不知道计算图，只能是一种运来计算数学运算的数据结构。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a1bee-f397-42a9-962f-d6ea819c0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N, D_in, H, D_out = 4, 100,20,10   # N是batch, D_in是输入维度，H为隐藏层维度，D_OUT为输出维度\n",
    "\n",
    "# 创建输入输出数据\n",
    "x = np.random.randn(N, D_in)\n",
    "Y = np.random.randn(N, D_out)\n",
    "\n",
    "# 初始化权重参数\n",
    "w1 = np.random.rand(D_in, H)\n",
    "W2 = np.random.rand(H, D_out)\n",
    "\n",
    "# 学习率\n",
    "lr = le-6\n",
    "\n",
    "for t in range(500):\n",
    "    # 前向过程\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0 )\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # 计算损失函数\n",
    "    loss = np.square(y_pred -y).sum()\n",
    "    print(t, loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
